# Databricks notebook source
# ================================================================
# SILVER LAYER - LIMPIEZA Y VALIDACIÃ“N (VERSIÃ“N MANAGED TABLE)
# ================================================================

print("ğŸ§¹ Iniciando transformaciones Silver...")
print("=" * 60)

from pyspark.sql.functions import *
from pyspark.sql.types import *

# ================================================================
# PASO 1: LEER BRONZE LAYER
# ================================================================

print("\nğŸ“– Leyendo Bronze layer...")

df_bronze = spark.table("bronze_ventas")

print(f"âœ… Registros en Bronze: {df_bronze.count()}")
df_bronze.show(3)

# ================================================================
# PASO 2: TRANSFORMACIONES SILVER
# ================================================================

print("\nğŸ”§ Aplicando transformaciones...")

df_silver = df_bronze \
    .filter(col("monto") > 0) \
    .filter(col("cantidad") > 0) \
    .withColumn("fecha", to_date(col("fecha"), "yyyy-MM-dd")) \
    .withColumn("monto_unitario", round(col("monto") / col("cantidad"), 2)) \
    .withColumn("processed_at", current_timestamp()) \
    .select(
        "transaction_id",
        "fecha",
        "tienda_id",
        "producto_id",
        "cantidad",
        "monto",
        "monto_unitario",
        "processed_at"
    )

print(f"âœ… Registros despuÃ©s de limpieza: {df_silver.count()}")
print("\nğŸ“Š Datos transformados:")
df_silver.show(5, truncate=False)

print("\nğŸ’° VerificaciÃ³n monto_unitario:")
df_silver.select("cantidad", "monto", "monto_unitario").show(5)

# ================================================================
# PASO 3: ESCRIBIR A SILVER LAYER
# ================================================================

print("\nğŸ’¾ Escribiendo a Silver layer...")

# Particionar por fecha Y escribir como tabla
df_silver.write \
    .format("delta") \
    .mode("overwrite") \
    .partitionBy("fecha") \
    .saveAsTable("silver_ventas_consolidadas")

print(f"âœ… Silver layer creado como tabla: silver_ventas_consolidadas")
print(f"âœ… Particionado por: fecha")

# ================================================================
# PASO 4: ANÃLISIS SILVER LAYER
# ================================================================

print("\nğŸ“Š ANÃLISIS DE DATOS SILVER\n")

df_silver_verify = spark.table("silver_ventas_consolidadas")

print("ğŸ“ˆ Ventas por dÃ­a:")
df_silver_verify.groupBy("fecha") \
    .agg(
        count("*").alias("num_transacciones"),
        sum("monto").alias("ventas_totales"),
        avg("monto").alias("ticket_promedio"),
        countDistinct("tienda_id").alias("num_tiendas")
    ) \
    .orderBy("fecha") \
    .show()

print("\nğŸ† Top 5 productos mÃ¡s vendidos:")
df_silver_verify.groupBy("producto_id") \
    .agg(
        sum("cantidad").alias("unidades_vendidas"),
        sum("monto").alias("ventas_totales")
    ) \
    .orderBy(desc("ventas_totales")) \
    .show(5)

print("\nğŸª Ventas por tienda:")
df_silver_verify.groupBy("tienda_id") \
    .agg(
        count("*").alias("num_transacciones"),
        sum("monto").alias("ventas_totales")
    ) \
    .orderBy(desc("ventas_totales")) \
    .show()

print("\n" + "="*60)
print("ğŸ‰ SILVER LAYER COMPLETO!")
print("="*60)