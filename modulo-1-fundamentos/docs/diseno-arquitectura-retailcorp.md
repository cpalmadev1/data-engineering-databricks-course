# Dise√±o de Arquitectura Data Engineering
## RetailCorp Chile - Propuesta T√©cnica

**Autor:** C√©sar Palma  
**Fecha:** 2 de Diciembre, 2024  
**Versi√≥n:** 1.0

---

## 1. Resumen Ejecutivo

RetailCorp Chile requiere modernizar su infraestructura de datos para 
soportar an√°lisis en tiempo real, reporting ejecutivo, y casos de uso 
avanzados de Machine Learning.

La soluci√≥n propuesta implementa una **arquitectura Data Lakehouse** 
utilizando **Medallion Architecture** (Bronze/Silver/Gold) sobre 
**Delta Lake**, con dise√±o **cloud-agnostic** que funciona en 
Azure, AWS, o GCP.

Esta arquitectura permitir√°:
- Dashboard ejecutivo con latencia < 1 minuto
- Reducci√≥n de costos de storage vs soluci√≥n actual
- Escalabilidad a petabytes sin redise√±o
- Soporte para BI y ML desde misma plataforma

**Costo estimado:** $8,000-9,500 USD/mes (depende del cloud provider)

---

## 2. Contexto del Negocio

### 2.1 Situaci√≥n Actual

RetailCorp opera:
- 500 tiendas f√≠sicas (Arica a Punta Arenas)
- 1 e-commerce (retailcorp.cl)
- 1 app m√≥vil (iOS + Android)
- 5M miembros programa fidelizaci√≥n

**Volumen de datos:**
- 50M transacciones/mes (~1.6M/d√≠a)
- 2M visitas web diarias
- 500K usuarios activos app

**Problemas actuales:**
- Reportes tardan 2-3 d√≠as
- Sin visibilidad tiempo real de inventario
- Datos en silos (POS, web, app separados)
- Imposible hacer an√°lisis predictivo

### 2.2 Objetivos del Proyecto

1. **Dashboard ejecutivo** actualizado cada minuto
2. **An√°lisis diario inventario** listo 7 AM
3. **Reportes mensuales** autom√°ticos
4. **Sistema recomendaciones** ML
5. **Detecci√≥n anomal√≠as** en tiempo real

---

## 3. An√°lisis de Requerimientos

### 3.1 Metodolog√≠a de An√°lisis

Para cada requerimiento se evalu√≥:
- Latencia m√°xima aceptable
- Criticidad de actuar en tiempo real
- Volumen de datos
- Usuarios consumidores
- Tipo de procesamiento √≥ptimo (Batch/Streaming)

### 3.2 Requerimientos Detallados

#### Requerimiento 1: Dashboard Ejecutivo Tiempo Real

**Descripci√≥n:** CEO y VP Ventas necesitan ver m√©tricas de ventas actualizadas constantemente.

**M√©tricas requeridas:**
- Ventas totales del d√≠a (acumulado en vivo)
- Top 10 productos vendidos hoy
- Ventas por canal (tiendas vs web vs app)
- Comparaci√≥n vs mismo d√≠a a√±o anterior

**An√°lisis:**
- **Latencia requerida:** < 1 minuto
- **Tipo de procesamiento:** H√≠brido (Streaming + Batch)
  - Streaming: Ventas totales en tiempo real (ventana 1 minuto)
  - Batch: Top 10 productos (actualizaci√≥n diaria)
  - Batch: Comparaci√≥n hist√≥rica (pre-calculada)
- **Justificaci√≥n:** El CEO necesita ver tendencia actual para tomar decisiones durante el d√≠a, pero no requiere actualizaci√≥n segundo a segundo. Ventana de 1 minuto es suficiente y m√°s econ√≥mica que streaming puro.
- **Fuentes de datos:** POS (500 tiendas), E-commerce, App m√≥vil
- **Volumen:** ~67K transacciones/hora promedio, picos de ~150 tx/segundo
- **Criticidad:** Alta (decisiones de negocio)

---

#### Requerimiento 2: An√°lisis Diario de Inventario

**Descripci√≥n:** Gerentes de Log√≠stica necesitan reporte de inventario cada ma√±ana a las 7 AM.

**Informaci√≥n requerida:**
- Stock actual por producto por tienda
- Productos con menos de 7 d√≠as de inventario
- Proyecci√≥n de quiebre de stock
- Sugerencias autom√°ticas de reabastecimiento

**An√°lisis:**
- **Latencia requerida:** Disponible a las 7 AM (datos del d√≠a anterior)
- **Tipo de procesamiento:** Batch nocturno (01:00 AM)
- **Justificaci√≥n:** Los datos pueden esperar horas. Es m√°s eficiente procesar todo el d√≠a de una vez durante la madrugada. El equipo de log√≠stica trabaja de 8 AM a 6 PM, as√≠ que tener datos a las 7 AM es suficiente.
- **Fuentes de datos:** ERP (SAP) para inventario, Ventas para proyecciones
- **Volumen:** 500 tiendas √ó 50,000 productos = ~25M registros potenciales, filtrado a ~5M activos
- **Criticidad:** Media (operacional pero no urgente)

---

#### Requerimiento 3: Reportes Mensuales Ejecutivos

**Descripci√≥n:** Board de Directores requiere reportes consolidados el d√≠a 1 de cada mes.

**Informaci√≥n requerida:**
- P&L por categor√≠a de producto
- An√°lisis de m√°rgenes brutos y netos
- Performance por tienda y regi√≥n
- Tendencias vs a√±os anteriores

**An√°lisis:**
- **Latencia requerida:** Disponible d√≠a 1 del mes (datos mes anterior)
- **Tipo de procesamiento:** Batch mensual con pre-agregaci√≥n incremental
- **Justificaci√≥n:** Reportes mensuales no requieren tiempo real. Estrategia: pre-agregar diariamente en Gold, el d√≠a 1 solo sumar 30 d√≠as ya procesados (minutos en vez de horas).
- **Fuentes de datos:** Ventas consolidadas, Costos (ERP), Devoluciones
- **Volumen:** 30 d√≠as √ó 1.6M transacciones = ~48M registros/mes
- **Criticidad:** Media (importante pero no urgente)

---

#### Requerimiento 4: Sistema de Recomendaciones ML

**Descripci√≥n:** Mostrar recomendaciones personalizadas en web y app.

**Funcionalidad requerida:**
- "Clientes que compraron X tambi√©n compraron Y"
- Recomendaciones basadas en perfil de cliente
- Personalizaci√≥n por historial de navegaci√≥n

**An√°lisis:**
- **Latencia requerida:** 
  - Entrenamiento: Puede esperar d√≠as (semanal)
  - Inferencia: < 100ms (lectura tabla pre-calculada)
- **Tipo de procesamiento:** 
  - Batch para entrenar modelo (Domingo 2 AM, procesa semana completa)
  - Lectura r√°pida para servir (tabla Gold pre-calculada)
- **Justificaci√≥n:** Los modelos de recomendaci√≥n no necesitan actualizarse en tiempo real. Entrenar semanalmente con datos hist√≥ricos es suficiente. La inferencia es simplemente un lookup en tabla pre-calculada (producto_id ‚Üí [lista de recomendaciones]).
- **Fuentes de datos:** Historial compras (Silver), Clickstream app/web, Segmentaci√≥n clientes
- **Volumen:** 6 meses historial √ó 50M transacciones/mes = ~300M registros para entrenamiento
- **Capa consumida:** Silver para entrenamiento, Gold para servir
- **Criticidad:** Media (mejora experiencia pero no cr√≠tico)

---

#### Requerimiento 5: Detecci√≥n de Anomal√≠as

**Descripci√≥n:** Detectar patrones inusuales y posible fraude.

**Casos de uso:**
- Fraude en transacciones (tarjeta robada, ubicaci√≥n sospechosa)
- Ca√≠das s√∫bitas de ventas de productos
- Discrepancias entre inventario y ventas (posible robo)

**An√°lisis:**
- **Latencia requerida:** 
  - Fraude en transacciones: < 2 segundos (CR√çTICO)
  - Anomal√≠as de ventas: < 1 hora (no cr√≠tico)
  - Discrepancias inventario: Diario (no cr√≠tico)
- **Tipo de procesamiento:** 
  - **Streaming** para detecci√≥n de fraude transaccional
  - **Batch horario** para anomal√≠as de negocio
- **Justificaci√≥n:** 
  - Fraude requiere acci√≥n inmediata (bloquear transacci√≥n mientras cliente en caja)
  - Anomal√≠as de ventas pueden esperar (alertar al equipo cada hora es suficiente)
  - Discrepancias inventario se revisan diariamente
- **Fuentes de datos:** Transacciones en tiempo real, Patrones hist√≥ricos, Inventario
- **Volumen:** 
  - Streaming: ~150 transacciones/segundo en peak
  - Batch: 1.6M transacciones/d√≠a
- **Criticidad:** 
  - Fraude: MUY ALTA (p√©rdida directa de dinero)
  - Anomal√≠as: Media (operacional)

---

### 3.3 Resumen Comparativo

| # | Requerimiento | Latencia | Procesamiento | Volumen | Criticidad | Justificaci√≥n Clave |
|---|---------------|----------|---------------|---------|------------|---------------------|
| 1 | Dashboard Ejecutivo | < 1 min | Streaming + Batch | Alto | Alta | CEO necesita tendencia actual, no segundo a segundo |
| 2 | Inventario Diario | 7 AM | Batch | Medio | Media | Datos pueden esperar, m√°s eficiente nocturno |
| 3 | Reportes Mensuales | D√≠a 1 mes | Batch | Alto | Media | Pre-agregaci√≥n diaria reduce tiempo procesamiento |
| 4 | Recomendaciones ML | < 100ms lectura | Batch entrenamiento | Muy Alto | Media | Modelo semanal suficiente, inferencia es lookup |
| 5a | Fraude Transaccional | < 2 seg | Streaming | Alto | Muy Alta | Cada segundo cuenta, p√©rdida directa dinero |
| 5b | Anomal√≠as Negocio | < 1 hora | Batch horario | Medio | Media | No requiere acci√≥n inmediata |

---

### 3.4 Decisi√≥n Arquitect√≥nica Resultante

Basado en este an√°lisis:

‚úÖ **Arquitectura H√≠brida (Lambda)** es la opci√≥n √≥ptima:
- **Streaming** solo para casos cr√≠ticos tiempo real (Dashboard RT, Fraude)
- **Batch** para todo lo dem√°s (mayor√≠a de los casos)
- **Balance** entre costo y funcionalidad

‚ùå **Todo Streaming:** Sobre-ingenier√≠a, costos 3-4x mayores sin beneficio real

‚ùå **Todo Batch:** No cumple requerimientos tiempo real (Dashboard, Fraude)

| Req | Descripci√≥n | Latencia | Procesamiento | Justificaci√≥n |
|-----|-------------|----------|---------------|---------------|
| 1 | Dashboard Ejecutivo RT | < 1 min | Streaming | CEO necesita ver ventas actuales |
| 2 | Inventario Diario | 7 AM | Batch | Datos pueden esperar noche |
| 3 | Reportes Mensuales | D√≠a 1 mes | Batch | No cr√≠tico tiempo real |
| 4 | Recomendaciones ML | < 1 seg lectura | Batch streaming | Modelo pre-calculado |
| 5 | Detecci√≥n Fraude | < 2 seg | Streaming | Cr√≠tico actuar inmediato |

---

## 4. Decisiones Arquitect√≥nicas

### 4.1 Storage: Data Lakehouse

**Decisi√≥n:** Implementar **Data Lakehouse** con **Delta Lake**

**Alternativas consideradas:**
- ‚ùå Data Warehouse: Inflexible, caro, solo datos estructurados
- ‚ùå Data Lake tradicional: Riesgo de "data swamp", sin ACID
- ‚úÖ Data Lakehouse: Combina flexibilidad + calidad

**Justificaci√≥n:**

RetailCorp necesita:
- ‚úÖ Almacenar datos estructurados (ventas) Y no estructurados (im√°genes)
- ‚úÖ Soportar BI (dashboards) Y ML (recomendaciones)
- ‚úÖ ACID transactions (para UPDATE inventario)
- ‚úÖ Costos bajos de storage

**Solo Data Lakehouse cumple todos estos requisitos.**

**Tecnolog√≠a:**
- Formato: **Delta Lake** (open source)
- Storage: ADLS Gen2 (Azure) / S3 (AWS) / Cloud Storage (GCP)
- Costo: ~$0.02/GB/mes

---

### 4.2 Medallion Architecture

**Decisi√≥n:** Implementar arquitectura de 3 capas (Bronze/Silver/Gold)

**Estructura:**
```
ü•â BRONZE (Raw Zone) - ~200MB/d√≠a
‚îú‚îÄ Datos crudos sin transformar
‚îú‚îÄ Formato original (CSV, JSON)
‚îú‚îÄ Inmutable (append-only)
‚îú‚îÄ Particionado: /year=YYYY/month=MM/day=DD/
‚îî‚îÄ Retenci√≥n: 365 d√≠as

ü•à SILVER (Cleaned Zone) - ~150MB/d√≠a
‚îú‚îÄ Datos limpios y validados
‚îú‚îÄ Sin duplicados
‚îú‚îÄ Formato Delta Lake
‚îú‚îÄ Schema enforcement
‚îî‚îÄ Retenci√≥n: 365 d√≠as

ü•á GOLD (Business Zone) - ~20MB/d√≠a
‚îú‚îÄ Agregaciones pre-calculadas
‚îú‚îÄ Modelado dimensional
‚îú‚îÄ Optimizado para BI/ML
‚îî‚îÄ Retenci√≥n: 1,095 d√≠as (3 a√±os)
```

**Justificaci√≥n:**

- ‚úÖ **Separation of concerns:** Cada capa tiene prop√≥sito claro
- ‚úÖ **Reprocessing:** Si algo falla en Silver/Gold, reprocesas desde Bronze
- ‚úÖ **Auditor√≠a:** Bronze guarda datos originales
- ‚úÖ **Performance:** Gold optimizado para consultas r√°pidas
- ‚úÖ **Costos:** Compresi√≥n reduce de 200MB ‚Üí 20MB

---

### 4.3 Batch vs Streaming

**Decisi√≥n:** Arquitectura **h√≠brida** (Lambda Architecture)

| Caso de Uso | Procesamiento | Frecuencia | Justificaci√≥n |
|-------------|---------------|------------|---------------|
| Dashboard RT | **Streaming** | Continuo | CEO requiere datos < 1 min |
| Inventario | **Batch** | 01:00 AM | Puede esperar horas |
| Reportes | **Batch** | Mensual | No cr√≠tico tiempo real |
| ML Training | **Batch** | Semanal | Modelos se entrenan offline |
| ML Serving | **Lectura** | < 100ms | Leer tabla pre-calculada |
| Fraude | **Streaming** | Continuo | Cr√≠tico bloquear inmediato |
| Anomal√≠as | **Batch** | Cada hora | No requiere acci√≥n inmediata |

**Trade-off de costos:**

| Opci√≥n | Costo/mes | Latencia | Cu√°ndo usar |
|--------|-----------|----------|-------------|
| Todo Streaming | $12,000 | Segundos | ‚ùå Sobre-ingenier√≠a |
| Todo Batch | $3,000 | Horas | ‚ùå No cumple req RT |
| **H√≠brido** | **$8,500** | **√ìptimo** | **‚úÖ Balance costo/beneficio** |

---

### 4.4 Stack Tecnol√≥gico Multi-Cloud

**Decisi√≥n:** Dise√±o **cloud-agnostic** con preferencia Azure (experiencia actual)

**Componentes principales:**

| Funci√≥n | Azure | AWS | GCP | Decisi√≥n |
|---------|-------|-----|-----|----------|
| Storage | ADLS Gen2 | S3 ‚≠ê | Cloud Storage | Cualquiera funciona |
| Compute | Databricks | Databricks | Dataproc | **Databricks** ‚úÖ |
| Streaming | Event Hubs | Kinesis | Pub/Sub | Depende del cloud |
| Orchestration | Databricks Workflows | Databricks Workflows | Composer | **Databricks** ‚úÖ |
| BI | Power BI ‚≠ê | QuickSight | Looker | **Power BI** (Latam) |

‚≠ê = M√°s com√∫n en el mercado

**Justificaci√≥n:**

1. **Databricks everywhere:** Mismo c√≥digo PySpark en Azure/AWS/GCP
2. **Delta Lake:** Open source, no vendor lock-in
3. **Power BI:** M√°s familiar para ejecutivos chilenos
4. **Portabilidad:** Cambiar de cloud = cambiar nombres herramientas, no arquitectura

**Recomendaci√≥n inicial: Azure**
- Equipo ya tiene experiencia
- Menor curva aprendizaje
- Integraci√≥n nativa con Power BI

**Plan futuro:** Si el negocio crece, evaluar AWS (m√°s econ√≥mico a gran escala)

---

## 5. Pipeline Ejemplo: Ventas

### 5.1 Flujo End-to-End

El pipeline de ventas consolida datos de 3 canales diferentes y los procesa a trav√©s de la arquitectura Medallion para servir m√∫ltiples casos de uso.

#### Paso 1: Ingesta - Tres Canales Diferentes

**Canal 1: POS Tiendas F√≠sicas**
- **Fuente:** 500 tiendas, cada una con sistema POS local
- **Formato:** CSVs generados cada 15 minutos
- **Mecanismo:** Azure Data Factory ejecuta pipeline programado cada 15 minutos
- **Proceso:**
  1. Data Factory conecta via SFTP/REST API a cada tienda
  2. Descarga CSVs generados en √∫ltimos 15 min
  3. Copia archivos a Bronze layer sin transformaci√≥n
- **Volumen:** ~100K transacciones/hora en horario normal, ~250K en peak hours
- **Destino:** `/bronze/ventas_pos/year=2024/month=12/day=02/hour=15/tienda_001.csv`

**Canal 2: E-commerce Web**
- **Fuente:** Base de datos PostgreSQL transaccional
- **Formato:** Tabla `transactions` con datos estructurados
- **Mecanismo:** Change Data Capture (CDC) cada 5 minutos via Data Factory
- **Proceso:**
  1. Data Factory monitorea cambios en PostgreSQL
  2. Extrae solo nuevas transacciones (incremental)
  3. Escribe como Delta Lake directamente en Bronze
- **Volumen:** ~20K transacciones/hora (continuo 24/7)
- **Destino:** `/bronze/ecommerce_transacciones/` (Delta Lake con timestamp)

**Canal 3: App M√≥vil**
- **Fuente:** Eventos de app enviados a REST API
- **Formato:** JSON events (compra completada, item agregado a carrito, etc.)
- **Mecanismo:** API ‚Üí Azure Event Hubs ‚Üí Databricks Streaming
- **Proceso:**
  1. App env√≠a evento POST a API Gateway
  2. API publica mensaje en Event Hubs (buffer)
  3. Databricks Structured Streaming consume continuamente
  4. Escribe a Bronze en micro-batches (cada 30 segundos)
- **Volumen:** ~50 eventos/segundo promedio, picos de ~200/seg
- **Destino:** `/bronze/app_eventos/year=2024/month=12/day=02/hour=15/` (Delta Lake)

**Resultado Paso 1:**
```
/bronze/
‚îú‚îÄ‚îÄ ventas_pos/
‚îÇ   ‚îú‚îÄ‚îÄ year=2024/month=12/day=02/hour=09/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tienda_001_09-00.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tienda_002_09-00.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (500 archivos)
‚îÇ   ‚îî‚îÄ‚îÄ year=2024/month=12/day=02/hour=10/
‚îÇ       ‚îî‚îÄ‚îÄ ... (500 archivos cada 15 min)
‚îÇ
‚îú‚îÄ‚îÄ ecommerce_transacciones/
‚îÇ   ‚îî‚îÄ‚îÄ _delta_log/  (Delta Lake format)
‚îÇ
‚îî‚îÄ‚îÄ app_eventos/
    ‚îî‚îÄ‚îÄ year=2024/month=12/day=02/hour=09/
        ‚îî‚îÄ‚îÄ _delta_log/  (Delta Lake format)
```

---

#### Paso 2: Bronze ‚Üí Silver - Limpieza y Consolidaci√≥n

**Job Databricks:** `bronze_to_silver_ventas`  
**Frecuencia:** Cada hora (ej: 01:00, 02:00, 03:00...)  
**Cluster:** Auto-scaling 2-10 workers, termina autom√°ticamente al finalizar  
**C√≥digo:** PySpark

**Transformaciones aplicadas:**

**1. Unificar Esquema:**
```python
# POS (CSV) - Schema variable por tienda
tienda_001: tienda_id, fecha_venta, cod_producto, cantidad, precio
tienda_002: store_id, sale_date, item_code, qty, amount

# E-commerce (PostgreSQL)
order_id, created_at, product_id, quantity, unit_price, customer_id

# App (JSON)
{
  "event_id": "...",
  "timestamp": "...",
  "product_id": "...",
  "quantity": 1,
  "price": 19990,
  "user_id": "..."
}

# RESULTADO UNIFICADO:
transaction_id (UUID generado)
fecha_hora (timestamp UTC-3)
canal (enum: 'POS', 'WEB', 'APP')
tienda_id (nullable para web/app)
cliente_id
producto_id
cantidad (int)
monto_unitario (decimal)
monto_total (decimal = cantidad √ó monto_unitario)
descuento (decimal, default 0)
estado (enum: 'completado', 'cancelado', 'pendiente')
metadata (map con info adicional espec√≠fica del canal)
```

**2. Deduplicaci√≥n:**
```python
# Eliminar duplicados por transaction_id √∫nico
df_silver = df_bronze \
  .dropDuplicates(["transaction_id"]) \
  .filter(col("transaction_id").isNotNull())

# Log: Registros duplicados encontrados
# 2024-12-02: 1,247 duplicados de 1,603,451 total (0.08%)
```

**3. Validaci√≥n:**
```python
# Reglas de calidad
df_silver = df_silver \
  .filter(col("monto_total") > 0) \              # Montos positivos
  .filter(col("monto_total") <= 10000000) \      # Monto m√°ximo razonable (10M CLP)
  .filter(col("cantidad") > 0) \                 # Cantidad positiva
  .filter(col("cantidad") <= 1000) \             # Cantidad m√°xima razonable
  .filter(col("fecha_hora").isNotNull()) \       # Fecha obligatoria
  .filter(col("producto_id").isNotNull())        # Producto obligatorio

# Registros inv√°lidos ‚Üí tabla separada para auditor√≠a
# /silver/ventas_rechazadas/ (para investigaci√≥n posterior)
```

**4. Normalizaci√≥n:**
```python
# Estandarizar formatos
df_silver = df_silver \
  .withColumn("fecha_hora", 
    to_timestamp(col("fecha_hora"), "yyyy-MM-dd HH:mm:ss")) \
  .withColumn("monto_unitario", round(col("monto_unitario"), 2)) \
  .withColumn("monto_total", round(col("monto_total"), 2)) \
  .withColumn("canal", upper(col("canal"))) \  # POS, WEB, APP (may√∫sculas)
  .withColumn("estado", lower(col("estado")))  # completado, cancelado (min√∫sculas)
```

**5. Enriquecimiento:**
```python
# Join con dimensiones para agregar contexto
df_silver = df_silver \
  .join(productos_dim, "producto_id", "left") \
    .withColumn("nombre_producto", col("productos_dim.nombre")) \
    .withColumn("categoria", col("productos_dim.categoria")) \
    .withColumn("marca", col("productos_dim.marca")) \
  .join(tiendas_dim, "tienda_id", "left") \
    .withColumn("region", col("tiendas_dim.region")) \
    .withColumn("tamano_tienda", col("tiendas_dim.tamano")) \
  .join(clientes_dim, "cliente_id", "left") \
    .withColumn("segmento_cliente", col("clientes_dim.segmento"))

# Resultado: Tabla consolidada con contexto completo
```

**Escritura a Silver:**
```python
df_silver.write \
  .format("delta") \
  .mode("append") \  # Siempre append, nunca overwrite
  .partitionBy("fecha", "canal") \  # Partition para queries r√°pidos
  .option("mergeSchema", "true") \  # Permite schema evolution
  .save("/silver/ventas_consolidadas")
```

**Resultado Paso 2:**
```
/silver/ventas_consolidadas/
‚îú‚îÄ‚îÄ fecha=2024-12-02/canal=POS/
‚îÇ   ‚îî‚îÄ‚îÄ part-00000-xxx.parquet
‚îú‚îÄ‚îÄ fecha=2024-12-02/canal=WEB/
‚îÇ   ‚îî‚îÄ‚îÄ part-00001-xxx.parquet
‚îú‚îÄ‚îÄ fecha=2024-12-02/canal=APP/
‚îÇ   ‚îî‚îÄ‚îÄ part-00002-xxx.parquet
‚îî‚îÄ‚îÄ _delta_log/
    ‚îú‚îÄ‚îÄ 00000000000000000000.json
    ‚îî‚îÄ‚îÄ 00000000000000000001.json

Esquema final Silver:
- transaction_id: string (unique)
- fecha_hora: timestamp
- fecha: date (partition key)
- canal: string (partition key: POS/WEB/APP)
- tienda_id: string (nullable)
- cliente_id: string
- producto_id: string
- nombre_producto: string (enriquecido)
- categoria: string (enriquecido)
- marca: string (enriquecido)
- cantidad: integer
- monto_unitario: decimal(10,2)
- monto_total: decimal(10,2)
- descuento: decimal(10,2)
- estado: string
- region: string (enriquecido)
- segmento_cliente: string (enriquecido)
- metadata: map<string,string>

Volumen: ~1.6M registros/d√≠a = ~150MB/d√≠a (Delta Lake comprimido)
```

---

#### Paso 3: Silver ‚Üí Gold - Agregaciones por Caso de Uso

Desde Silver se crean m√∫ltiples tablas Gold, cada una optimizada para un caso de uso espec√≠fico.

**Gold 1: Dashboard Tiempo Real (Streaming)**

**Job:** `silver_to_gold_dashboard_realtime`  
**Tipo:** Structured Streaming (corre 24/7)  
**Ventana:** 1 minuto  
**Cluster:** 2 workers dedicados (no se apaga)
```python
# Query streaming con ventana tumbling de 1 minuto
df_gold_rt = spark.readStream \
  .format("delta") \
  .table("silver.ventas_consolidadas") \
  .withWatermark("fecha_hora", "2 minutes") \
  .groupBy(
    window(col("fecha_hora"), "1 minute"),
    col("canal")
  ) \
  .agg(
    sum("monto_total").alias("ventas_totales"),
    count("transaction_id").alias("num_transacciones"),
    avg("monto_total").alias("ticket_promedio"),
    countDistinct("cliente_id").alias("clientes_unicos")
  )

# Escritura a Gold (streaming)
df_gold_rt.writeStream \
  .format("delta") \
  .outputMode("append") \
  .option("checkpointLocation", "/checkpoints/dashboard_rt") \
  .trigger(processingTime="1 minute") \
  .start("/gold/dashboards/ventas_tiempo_real")
```

**Salida:**
```
/gold/dashboards/ventas_tiempo_real/
Columnas:
- window_start: timestamp (ej: 2024-12-02 10:15:00)
- window_end: timestamp (ej: 2024-12-02 10:16:00)
- canal: string
- ventas_totales: decimal
- num_transacciones: bigint
- ticket_promedio: decimal
- clientes_unicos: bigint

Actualizaci√≥n: Cada 1 minuto (streaming continuo)
Consumidor: Power BI Dashboard (CEO/VP Ventas)
Latencia: < 1 minuto end-to-end
```

---

**Gold 2: Reportes Diarios (Batch)**

**Job:** `silver_to_gold_reportes_diarios`  
**Frecuencia:** Diario 01:00 AM  
**Cluster:** Auto-scaling 4-8 workers
```python
# Procesa d√≠a completo anterior
fecha_proceso = date.today() - timedelta(days=1)

# Top 10 productos
df_top_productos = spark.read \
  .format("delta") \
  .table("silver.ventas_consolidadas") \
  .filter(col("fecha") == fecha_proceso) \
  .filter(col("estado") == "completado") \
  .groupBy("producto_id", "nombre_producto", "categoria") \
  .agg(
    sum("cantidad").alias("unidades_vendidas"),
    sum("monto_total").alias("ventas_totales"),
    count("transaction_id").alias("num_transacciones")
  ) \
  .withColumn("ranking", 
    row_number().over(Window.orderBy(desc("ventas_totales")))
  ) \
  .filter(col("ranking") <= 10)

# Ventas por regi√≥n
df_ventas_region = spark.read \
  .format("delta") \
  .table("silver.ventas_consolidadas") \
  .filter(col("fecha") == fecha_proceso) \
  .groupBy("fecha", "region", "categoria") \
  .agg(
    sum("monto_total").alias("ventas_totales"),
    avg("monto_total").alias("ticket_promedio"),
    count(when(col("canal") == "POS", 1)).alias("ventas_tienda"),
    count(when(col("canal") == "WEB", 1)).alias("ventas_web"),
    count(when(col("canal") == "APP", 1)).alias("ventas_app")
  )

# Comparaci√≥n YoY (Year over Year)
fecha_a√±o_anterior = fecha_proceso - timedelta(days=365)

df_comparacion_yoy = df_ventas_region.alias("actual") \
  .join(
    spark.read.format("delta")
      .table("gold.reportes.ventas_diarias")
      .filter(col("fecha") == fecha_a√±o_anterior)
      .alias("anterior"),
    on=["region", "categoria"],
    how="left"
  ) \
  .withColumn("crecimiento_yoy_pct",
    ((col("actual.ventas_totales") - col("anterior.ventas_totales")) / 
     col("anterior.ventas_totales") * 100)
  )

# Escribir a Gold
df_top_productos.write \
  .format("delta") \
  .mode("append") \
  .partitionBy("fecha") \
  .save("/gold/reportes/top_productos_diarios")

df_comparacion_yoy.write \
  .format("delta") \
  .mode("append") \
  .partitionBy("fecha") \
  .save("/gold/reportes/ventas_diarias")
```

**Salida:**
```
/gold/reportes/ventas_diarias/
Actualizaci√≥n: Diaria (01:00 AM)
Consumidor: Analistas de negocio, Gerentes
Formato: Delta Lake optimizado con Z-Order
Volumen: ~5MB/d√≠a

/gold/reportes/top_productos_diarios/
Actualizaci√≥n: Diaria (01:00 AM)
Consumidor: Category Managers, Buyers
```

---

**Gold 3: Features para Machine Learning (Batch Semanal)**

**Job:** `silver_to_gold_ml_features`  
**Frecuencia:** Semanal (Domingos 02:00 AM)  
**Cluster:** Auto-scaling 8-16 workers (proceso pesado)
```python
# RFM Score por cliente (Recency, Frequency, Monetary)
from pyspark.sql.functions import datediff, current_date

df_rfm = spark.read \
  .format("delta") \
  .table("silver.ventas_consolidadas") \
  .filter(col("estado") == "completado") \
  .groupBy("cliente_id") \
  .agg(
    # Recency: d√≠as desde √∫ltima compra
    datediff(current_date(), max("fecha")).alias("recency"),
    
    # Frequency: n√∫mero de transacciones √∫ltimos 90 d√≠as
    count(when(col("fecha") >= current_date() - 90, 1)).alias("frequency"),
    
    # Monetary: valor total gastado √∫ltimos 90 d√≠as
    sum(when(col("fecha") >= current_date() - 90, col("monto_total"))).alias("monetary")
  )

# Product Affinity (productos comprados juntos)
from pyspark.ml.fpm import FPGrowth

# Transacciones con items comprados
transactions = spark.read \
  .format("delta") \
  .table("silver.ventas_consolidadas") \
  .groupBy("transaction_id") \
  .agg(collect_list("producto_id").alias("items"))

# FP-Growth para frequent itemsets
fpGrowth = FPGrowth(itemsCol="items", minSupport=0.01, minConfidence=0.5)
model = fpGrowth.fit(transactions)

# Reglas de asociaci√≥n: Si compra X ‚Üí probablemente compre Y
association_rules = model.associationRules \
  .withColumn("lift", col("confidence") / col("consequent_support")) \
  .filter(col("lift") > 1.5)  # Solo reglas con lift significativo

# Escribir a Gold
df_rfm.write \
  .format("delta") \
  .mode("overwrite") \  # Overwrite cada semana
  .save("/gold/machine_learning/rfm_scores")

association_rules.write \
  .format("delta") \
  .mode("overwrite") \
  .save("/gold/machine_learning/recomendaciones_producto")
```

**Salida:**
```
/gold/machine_learning/recomendaciones_producto/
Estructura:
- antecedent: array<string> (ej: ["producto_123"])
- consequent: array<string> (ej: ["producto_456", "producto_789"])
- confidence: double (probabilidad de compra)
- lift: double (qu√© tan fuerte es la asociaci√≥n)

Actualizaci√≥n: Semanal (Domingos)
Consumidor: Sistema de recomendaciones en web/app
Volumen: ~2MB (solo reglas significativas)

Uso en producci√≥n:
- API REST consulta esta tabla
- Cliente ve producto_123
- API retorna productos en "consequent" ordenados por confidence
- Latencia: < 100ms (simple lookup)
```

---

### 5.2 Volumetr√≠a y Performance

**Resumen de vol√∫menes por capa:**
```
BRONZE (Raw data ingestion)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Input: 1.6M transacciones/d√≠a
Formatos: CSV (POS) + Delta (E-com + App)
Tama√±o: ~200MB/d√≠a comprimido
Retenci√≥n: 365 d√≠as = ~73GB/a√±o
Costo storage: $73GB √ó $0.02 = $1.46/mes

SILVER (Cleaned + consolidated)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Input: 1.6M transacciones/d√≠a (post-deduplicaci√≥n)
Formato: Delta Lake con particionado
Tama√±o: ~150MB/d√≠a (optimizaci√≥n Delta)
Retenci√≥n: 365 d√≠as = ~55GB/a√±o
Costo storage: $55GB √ó $0.02 = $1.10/mes

GOLD (Business aggregations)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Dashboard RT: ~10KB por ventana 1 min = ~14MB/d√≠a
Reportes diarios: ~5MB/d√≠a
ML features: ~2MB/semana
Total: ~20MB/d√≠a
Retenci√≥n: 3 a√±os = ~22GB total
Costo storage: $22GB √ó $0.02 = $0.44/mes

TOTAL STORAGE: ~150GB = $3/mes 
(incre√≠blemente econ√≥mico gracias a compresi√≥n Delta Lake)
```

**Tiempos de procesamiento:**
```
JOB: bronze_to_silver_ventas (1 hora de datos)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Input: ~100K transacciones
Cluster: 2-4 workers (auto-scaling)
Tiempo: 2-3 minutos
Costo: ~$0.10 por ejecuci√≥n
Frecuencia: 24 veces/d√≠a
Costo diario: ~$2.40

JOB: silver_to_gold_dashboard_realtime (streaming)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Cluster: 2 workers dedicados 24/7
Latencia: < 1 minuto end-to-end
Costo: ~$120/mes (cluster always-on)

JOB: silver_to_gold_reportes_diarios (d√≠a completo)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Input: 1.6M transacciones
Cluster: 4-8 workers
Tiempo: 5-8 minutos
Costo: ~$0.50 por ejecuci√≥n
Frecuencia: 1 vez/d√≠a
Costo mensual: ~$15

JOB: silver_to_gold_ml_features (semana completa)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Input: ~11M transacciones (7 d√≠as)
Cluster: 8-16 workers
Tiempo: 30-45 minutos
Costo: ~$5 por ejecuci√≥n
Frecuencia: 1 vez/semana
Costo mensual: ~$20
```

**Latencias end-to-end:**
```
POS Tienda ‚Üí Bronze ‚Üí Silver ‚Üí Gold Dashboard ‚Üí Power BI
‚îú‚îÄ POS genera CSV: 0-15 min (cada 15 min)
‚îú‚îÄ Data Factory ingesta: 2-3 min
‚îú‚îÄ Bronze ‚Üí Silver: 2-3 min (ejecuta cada hora)
‚îú‚îÄ Silver ‚Üí Gold streaming: < 1 min
‚îî‚îÄ Power BI refresh: 30 seg

LATENCIA TOTAL: 20-25 minutos (peor caso)
LATENCIA T√çPICA: 5-10 minutos

E-commerce ‚Üí Bronze ‚Üí Silver ‚Üí Gold Dashboard ‚Üí Power BI
‚îú‚îÄ CDC detecta cambio: < 5 min
‚îú‚îÄ Bronze ‚Üí Silver: 2-3 min
‚îú‚îÄ Silver ‚Üí Gold streaming: < 1 min
‚îî‚îÄ Power BI refresh: 30 seg

LATENCIA TOTAL: 8-10 minutos

App M√≥vil ‚Üí Bronze ‚Üí Silver ‚Üí Gold Dashboard ‚Üí Power BI
‚îú‚îÄ Event Hubs buffer: < 30 seg
‚îú‚îÄ Streaming a Bronze: < 30 seg
‚îú‚îÄ Bronze ‚Üí Silver: 2-3 min
‚îú‚îÄ Silver ‚Üí Gold streaming: < 1 min
‚îî‚îÄ Power BI refresh: 30 seg

LATENCIA TOTAL: 4-5 minutos (m√°s r√°pido por ser streaming end-to-end)
```

## 6. Estimaci√≥n de Costos

### 6.1 Comparaci√≥n Multi-Cloud

| Componente | Azure | AWS | GCP |
|------------|-------|-----|-----|
| Storage (50TB) | $900/mes | $1,150/mes | $1,000/mes |
| Compute Batch | $1,200/mes | $1,000/mes | $1,100/mes |
| Compute Streaming | $4,000/mes | $3,500/mes | $3,800/mes |
| Event Platform | $800/mes | $600/mes | $700/mes |
| Databricks | $1,500/mes | $1,500/mes | $1,500/mes |
| BI Tools | $500/mes | $300/mes | $400/mes |
| Networking | $500/mes | $400/mes | $450/mes |
| **TOTAL** | **$9,400/mes** | **$8,450/mes** | **$8,950/mes** |

**AWS es ~10% m√°s econ√≥mico** a esta escala.

### 6.2 Optimizaciones de Costo

1. **Auto-scaling:** Clusters se apagan cuando no se usan
2. **Spot instances:** Reducci√≥n 60-70% en compute no cr√≠tico
3. **Cold storage:** Datos >90 d√≠as a tier econ√≥mico
4. **Particionamiento:** Queries solo leen datos necesarios

**Costo optimizado estimado: $7,000-7,500/mes**

---

## 7. Riesgos y Mitigaciones

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| Data quality issues | Alta | Alto | Great Expectations + alertas |
| Costos exceden presupuesto | Media | Alto | Monitoring + alertas costos |
| Performance degradation | Media | Medio | Optimization (Z-Order, clustering) |
| Vendor lock-in | Baja | Alto | Delta Lake open source |
| Skills gap equipo | Media | Medio | Training + documentaci√≥n |

---

## 8. Diagramas

### 8.1 Arquitectura General End-to-End

![Arquitectura Data Lakehouse RetailCorp](../diagramas/arquitectura-general.png)

*Figura 1: Arquitectura completa cloud-agnostic mostrando flujo desde fuentes hasta consumo*

---

## 9. Conclusiones

La arquitectura propuesta cumple todos los requerimientos de RetailCorp:

‚úÖ Dashboard tiempo real (< 1 min latencia)  
‚úÖ Inventario diario automatizado (7 AM)  
‚úÖ Reportes mensuales ejecutivos  
‚úÖ Base para ML (recomendaciones, anomal√≠as)  
‚úÖ Escalable a crecimiento futuro  
‚úÖ Costo-efectiva ($8,000-9,000/mes)  
‚úÖ Cloud-agnostic (no vendor lock-in)

**Recomendaci√≥n de implementaci√≥n:**

**Fase 1 (Mes 1-2):** MVP
- Bronze + Silver para ventas
- Dashboard b√°sico streaming
- Azure (experiencia actual)

**Fase 2 (Mes 3-4):** Expansi√≥n
- Gold layer completo
- Todos los casos de uso
- Optimizaciones performance

**Fase 3 (Mes 5-6):** Advanced
- ML en producci√≥n
- Governance (Unity Catalog)
- Monitoring avanzado

---

## 10. Referencias

- [Databricks: What is a Data Lakehouse?](https://www.databricks.com/glossary/data-lakehouse)
- [Delta Lake Documentation](https://docs.delta.io/)
- [Azure Databricks Best Practices](https://learn.microsoft.com/azure/databricks/)
- [AWS EMR Best Practices](https://docs.aws.amazon.com/emr/)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)

---

**Fin del documento**
