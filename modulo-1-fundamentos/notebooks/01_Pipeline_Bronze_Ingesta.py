# Databricks notebook source
from pyspark.sql.functions import *

print("\nğŸ“– Leyendo tabla ventas_raw...")

# Leer tabla que creaste en Paso 2
df_raw = spark.table("ventas_raw")

# Verificar
num_registros = df_raw.count()
print(f"âœ… Registros leÃ­dos: {num_registros}")

# Mostrar primeros registros
print("\nğŸ“Š Vista previa datos:")
df_raw.show(5, truncate=False)

# Ver esquema
print("\nğŸ“‹ Esquema de datos:")
df_raw.printSchema()

# COMMAND ----------

print("\nâ° Agregando timestamp de ingesta...")

df_bronze = df_raw \
    .withColumn("ingested_at", current_timestamp()) \
    .withColumn("source", lit("csv_upload"))

print("âœ… Metadatos agregados")
df_bronze.show(3, truncate=False)

# COMMAND ----------

# ================================================================
# PASO 3: ESCRIBIR A BRONZE LAYER COMO TABLA DELTA
# ================================================================

print("\nğŸ’¾ Escribiendo a Bronze layer...")

# Crear tabla Delta administrada (no necesita path especÃ­fico)
df_bronze.write \
    .format("delta") \
    .mode("overwrite") \
    .saveAsTable("bronze_ventas")

print(f"âœ… Bronze layer creado como tabla: bronze_ventas")

# ================================================================
# PASO 4: VERIFICAR BRONZE LAYER
# ================================================================

print("\nğŸ” Verificando Bronze layer...")

# Leer desde Bronze
df_verify_bronze = spark.table("bronze_ventas")

bronze_count = df_verify_bronze.count()
print(f"âœ… Registros en Bronze: {bronze_count}")

print("\nğŸ“Š Datos en Bronze:")
df_verify_bronze.show(5, truncate=False)

print("\n" + "="*60)
print("ğŸ‰ BRONZE LAYER COMPLETO!")